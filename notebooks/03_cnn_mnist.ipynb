{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. 합성곱 신경망 - MNIST (CNN)\n",
    "\n",
    "이미지 분류에 특화된 CNN을 구현합니다.\n",
    "\n",
    "## 학습 목표\n",
    "- 합성곱(Convolution) 연산 이해\n",
    "- 풀링(Pooling) 연산 이해\n",
    "- CNN 구조 설계\n",
    "- MNIST 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 합성곱 연산 이해\n",
    "\n",
    "합성곱은 필터(커널)를 이미지 위에서 슬라이딩하며 특징을 추출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfs.nn.layers import Conv2d, MaxPool2d\n",
    "\n",
    "# 예시: 단일 이미지에 합성곱 적용\n",
    "conv = Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1)\n",
    "pool = MaxPool2d(kernel_size=2)\n",
    "\n",
    "# 입력: (batch=1, channels=1, H=28, W=28)\n",
    "x = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "# 합성곱 적용\n",
    "conv_out = conv(x)\n",
    "print(f\"Input: {x.shape}\")\n",
    "print(f\"After Conv: {conv_out.shape}\")\n",
    "\n",
    "# 풀링 적용\n",
    "pool_out = pool(conv_out)\n",
    "print(f\"After Pool: {pool_out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MNIST 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfs.utils.data import load_mnist\n",
    "from mlfs.utils.viz import plot_images\n",
    "\n",
    "# 이미지 형태로 로드 (flatten=False)\n",
    "X_train, y_train = load_mnist(train=True, flatten=False)\n",
    "X_test, y_test = load_mnist(train=False, flatten=False)\n",
    "\n",
    "print(f\"Train: {X_train.shape}\")\n",
    "print(f\"Test: {X_test.shape}\")\n",
    "\n",
    "# 샘플 확인\n",
    "plot_images(X_train[:10], labels=y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfs.nn.models import CNN\n",
    "from mlfs.nn.losses import CrossEntropyLoss\n",
    "from mlfs.nn.optim import Adam\n",
    "\n",
    "# CNN 모델 생성\n",
    "model = CNN(in_channels=1, num_classes=10, image_size=28)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 (작은 서브셋으로 빠른 테스트)\n",
    "n_samples = 10000  # 빠른 학습을 위해 일부만 사용\n",
    "X_train_sub = X_train[:n_samples]\n",
    "y_train_sub = y_train[:n_samples]\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "train_losses = []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    indices = torch.randperm(n_samples)\n",
    "    \n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        batch_idx = indices[i:i+batch_size]\n",
    "        X_batch = X_train_sub[batch_idx]\n",
    "        y_batch = y_train_sub[batch_idx]\n",
    "        \n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, y_batch)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    train_losses.append(epoch_loss / (n_samples // batch_size))\n",
    "    \n",
    "    # 테스트\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 배치로 테스트 (메모리 절약)\n",
    "        correct = 0\n",
    "        for i in range(0, len(X_test), batch_size):\n",
    "            X_batch = X_test[i:i+batch_size]\n",
    "            y_batch = y_test[i:i+batch_size]\n",
    "            pred = model.predict(X_batch)\n",
    "            correct += (pred == y_batch).sum().item()\n",
    "        test_acc = correct / len(X_test)\n",
    "    test_accs.append(test_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1:2d}: Loss = {train_losses[-1]:.4f}, Test Acc = {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(train_losses)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(test_accs)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Test Accuracy')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 결과 시각화\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model.predict(X_test[:20])\n",
    "\n",
    "plot_images(X_test[:20], labels=y_test[:20], predictions=predictions, n_rows=4, n_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 필터 시각화\n",
    "\n",
    "학습된 첫 번째 합성곱 레이어의 필터를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 Conv 레이어의 가중치\n",
    "filters = model.conv1.weight.detach()\n",
    "print(f\"Filter shape: {filters.shape}\")\n",
    "\n",
    "# 필터 시각화\n",
    "fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < filters.shape[0]:\n",
    "        ax.imshow(filters[i, 0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Learned Filters (Conv1)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 요약\n",
    "\n",
    "1. **합성곱층**: 지역적 특징 추출, 파라미터 공유\n",
    "2. **풀링층**: 공간 크기 축소, 위치 불변성\n",
    "3. **CNN 구조**: Conv → ReLU → Pool → ... → FC\n",
    "4. **성능**: MLP보다 적은 파라미터로 더 좋은 성능\n",
    "\n",
    "다음 노트북에서는 더 복잡한 **CIFAR-10** 데이터셋을 다룹니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
